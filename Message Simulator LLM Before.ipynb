{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c47fae-c527-4863-b2c3-c29f384c3808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (no policy): {'bytes': 29750496, 'msgs': 309901, 'time': 1.5149999999999897, 'avg_mae': 0.0, 'max_q': 65}\n",
      "Action summary: {'ALLOW': 30674, 'COMPRESS': 59225, 'AGGREGATE': 15033, 'SKIP': 5621}\n",
      "Max queue depth observed: 3\n",
      "RulePolicy: {'bytes': 6539280, 'msgs': 97730, 'time': 0.3500000000000002, 'avg_mae': 0.009605144268427145, 'max_q': 3}\n",
      "Action summary: {'ALLOW': 54206, 'COMPRESS': 29706, 'AGGREGATE': 23974, 'SKIP': 2886}\n",
      "Max queue depth observed: 4\n",
      "LLMPolicy: {'bytes': 7936416, 'msgs': 97524, 'time': 0.3550000000000002, 'avg_mae': 0.0033121292808495927, 'max_q': 4}\n"
     ]
    }
   ],
   "source": [
    "# message_opt_sim.py\n",
    "import json\n",
    "import simpy, math, random, heapq\n",
    "from collections import defaultdict\n",
    "from math import isfinite\n",
    "\n",
    "BITS_PER_BYTE = 8\n",
    "\n",
    "# -------------------- Link (network channel) --------------------\n",
    "class Link:\n",
    "    def __init__(self, env, u, v, bandwidth_bps, prop_delay_ms, capacity=32):   #udpated smaller queue depth\n",
    "        self.env = env\n",
    "        self.u, self.v = u, v\n",
    "        self.bps = bandwidth_bps\n",
    "        self.prop = prop_delay_ms / 1000.0\n",
    "        self.q = simpy.Store(env, capacity=capacity)   # finite queue -> backpressure\n",
    "        self.bytes_sent = 0\n",
    "        self.messages_sent = 0\n",
    "        self.max_q_depth = 0\n",
    "        env.process(self.run())\n",
    "\n",
    "    def send(self, size_bytes, payload):\n",
    "        # put() blocks if queue is full -> natural backpressure\n",
    "        self.bytes_sent += size_bytes\n",
    "        self.messages_sent += 1\n",
    "        self.max_q_depth = max(self.max_q_depth, len(self.q.items) + 1)\n",
    "        return self.q.put((size_bytes, payload))\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            size_bytes, payload = (yield self.q.get())\n",
    "            ser = (size_bytes * BITS_PER_BYTE) / self.bps\n",
    "            yield self.env.timeout(ser + self.prop)\n",
    "            payload[\"dst\"].inbox.put(payload)\n",
    "\n",
    "# -------------------- Queue-aware Rule Policy --------------------\n",
    "class RulePolicy:\n",
    "    \"\"\"\n",
    "    Realistic queue-aware policy:\n",
    "      - If tiny improvement and link is busy -> SKIP (shed low-value load)\n",
    "      - If queue has backlog -> AGGREGATE (batch for a short window)\n",
    "      - If small improvement -> COMPRESS (smaller payload)\n",
    "      - Else -> ALLOW\n",
    "    \"\"\"\n",
    "    def __init__(self, eps_small=0.05, eps_med=0.20, q_hi=1, agg_ms=20):\n",
    "        self.eps_small = eps_small\n",
    "        self.eps_med = eps_med\n",
    "        self.q_hi = q_hi\n",
    "        self.agg_ms = agg_ms\n",
    "\n",
    "    def decide(self, *, delta, queue_depth, util=None):\n",
    "        if delta < self.eps_small and queue_depth > 0:\n",
    "            return \"SKIP\", None, None\n",
    "        if queue_depth >= self.q_hi:\n",
    "            return \"AGGREGATE\", self.agg_ms, None\n",
    "        if delta < self.eps_med:\n",
    "            return \"COMPRESS\", None, 48  # bytes\n",
    "        return \"ALLOW\", None, 96         # bytes\n",
    "\n",
    "# -------------------- Node (distributed process) --------------------\n",
    "class Node:\n",
    "    def __init__(self, env, node_id, controller, policy):\n",
    "        self.env = env\n",
    "        self.id = node_id\n",
    "        self.ctrl = controller\n",
    "        self.policy = policy                    # may be None for baseline\n",
    "        self.neighbors = {}                     # v -> (link, weight)\n",
    "        self.inbox = simpy.Store(env)\n",
    "        self.dist = defaultdict(lambda: math.inf)\n",
    "        self.last_sent = defaultdict(lambda: math.inf)  # best value last sent per (v,s)\n",
    "        self.pending = {}                       # aggregation buffers\n",
    "        self.action_counts = defaultdict(int)   # instrumentation\n",
    "        env.process(self.recv_loop())\n",
    "\n",
    "    def add_neighbor(self, v, link, w):\n",
    "        self.neighbors[v] = (link, w)\n",
    "\n",
    "    def init_source(self, s):\n",
    "        if self.id == s:\n",
    "            self.dist[s] = 0.0\n",
    "            for v,(link,w) in self.neighbors.items():\n",
    "                self._maybe_send(v, s, self.dist[s] + w)\n",
    "\n",
    "    def _enqueue_send(self, link, payload, size_bytes):\n",
    "        self.ctrl.inflight += 1\n",
    "        link.send(size_bytes, payload)\n",
    "\n",
    "    def _maybe_send(self, v, s, d):\n",
    "        link,_ = self.neighbors[v]\n",
    "\n",
    "        # Baseline: always send full message\n",
    "        if self.policy is None:\n",
    "            msg = {\"kind\":\"RELAX\",\"src\":self,\"dst\":self.ctrl.nodes[v],\"s\":s,\"d\":d}\n",
    "            self.last_sent[(v,s)] = d\n",
    "            self._enqueue_send(link, msg, self.ctrl.size_model(\"RELAX\"))\n",
    "            return\n",
    "\n",
    "        old = self.last_sent[(v,s)]\n",
    "        delta = abs(d - old)\n",
    "        queue_depth = len(link.q.items)\n",
    "\n",
    "        action, param, size_bytes = self.policy.decide(\n",
    "        delta=delta, queue_depth=queue_depth, util=None\n",
    "        )\n",
    "        # action, param, size_bytes = self.policy.decide(\n",
    "        #     delta=delta, queue_depth=queue_depth, util=None\n",
    "        # )\n",
    "        \n",
    "        self.action_counts[action] += 1\n",
    "        if action == \"SKIP\":\n",
    "            return\n",
    "\n",
    "        if action == \"AGGREGATE\":\n",
    "            key = (v,s)\n",
    "            self.pending[key] = d\n",
    "            if (\"timer\", key) not in self.pending:\n",
    "                self.pending[(\"timer\", key)] = True\n",
    "                self.env.process(self._aggregate_after(param, v, s, link))\n",
    "            return\n",
    "\n",
    "        # ALLOW/COMPRESS -> send immediately\n",
    "        send_size = size_bytes if size_bytes is not None else self.ctrl.size_model(\"RELAX\")\n",
    "        msg = {\"kind\":\"RELAX\",\"src\":self,\"dst\":self.ctrl.nodes[v],\"s\":s,\"d\":d}\n",
    "        self.last_sent[(v,s)] = d\n",
    "        self._enqueue_send(link, msg, send_size)\n",
    "\n",
    "    def _aggregate_after(self, delay_ms, v, s, link):\n",
    "        yield self.env.timeout(delay_ms / 1000.0)\n",
    "        key = (v,s)\n",
    "        if key in self.pending:\n",
    "            d = self.pending.pop(key)\n",
    "            _ = self.pending.pop((\"timer\", key), None)\n",
    "            send_size = self.ctrl.size_model(\"RELAX\")\n",
    "            msg = {\"kind\":\"RELAX\",\"src\":self,\"dst\":self.ctrl.nodes[v],\"s\":s,\"d\":d}\n",
    "            self.last_sent[(v,s)] = d\n",
    "            self._enqueue_send(link, msg, send_size)\n",
    "        else:\n",
    "            _ = self.pending.pop((\"timer\", key), None)\n",
    "\n",
    "    def recv_loop(self):\n",
    "        while True:\n",
    "            msg = (yield self.inbox.get())\n",
    "            self.ctrl.inflight -= 1\n",
    "            if msg[\"kind\"] == \"RELAX\":\n",
    "                s, d = msg[\"s\"], msg[\"d\"]\n",
    "                if d < self.dist[s]:\n",
    "                    self.dist[s] = d\n",
    "                    for v,(link,w) in self.neighbors.items():\n",
    "                        self._maybe_send(v, s, self.dist[s] + w)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "class LLMPolicy:\n",
    "    \"\"\"\n",
    "    Real-LLM policy stub:\n",
    "    - Bins features (delta, queue_depth) to reduce distinct prompts.\n",
    "    - Calls `call_model_fn(prompt: str) -> str` that returns a JSON decision.\n",
    "    - Returns (action, param, size_bytes) like other policies.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 call_model_fn,\n",
    "                 bins_delta=(0.02, 0.1, 0.5, 1.0),\n",
    "                 bins_q=(0, 1, 2, 4, 8),\n",
    "                 agg_ms_choices=(5, 10, 20),\n",
    "                 compress_size=48,\n",
    "                 full_size=96,\n",
    "                 use_cache=True):\n",
    "        self.call_model_fn = call_model_fn\n",
    "        self.bins_delta = tuple(sorted(bins_delta))\n",
    "        self.bins_q = tuple(sorted(bins_q))\n",
    "        self.agg_ms_choices = agg_ms_choices\n",
    "        self.compress_size = compress_size\n",
    "        self.full_size = full_size\n",
    "        self.use_cache = use_cache\n",
    "        self._cache = {}  # (delta_bin, q_bin) -> (action, param, size_bytes)\n",
    "\n",
    "    # ---- helpers ----\n",
    "    def _bin(self, x, edges):\n",
    "        # place x into a discrete bin index: 0..len(edges)\n",
    "        for i, e in enumerate(edges):\n",
    "            if x < e:\n",
    "                return i\n",
    "        return len(edges)\n",
    "\n",
    "    def _mk_prompt(self, delta, qdepth, dbin, qbin):\n",
    "        # Keep the prompt small and deterministic so caching works well.\n",
    "        return f\"\"\"\n",
    "You are controlling message sending in a distributed shortest-path simulation.\n",
    "\n",
    "Inputs:\n",
    "- improvement_delta: {delta:.6f} (bin={dbin})\n",
    "- link_queue_depth: {qdepth} (bin={qbin})\n",
    "\n",
    "Goal:\n",
    "- Minimize total bytes and messages.\n",
    "- Keep accuracy high (prefer small error).\n",
    "- Avoid adding much latency; only aggregate briefly if helpful.\n",
    "\n",
    "Action space (choose exactly one):\n",
    "- \"ALLOW\": send now with full size {self.full_size}.\n",
    "- \"COMPRESS\": send now with smaller size {self.compress_size}.\n",
    "- \"AGGREGATE\": delay briefly to coalesce; choose param in ms from {list(self.agg_ms_choices)}.\n",
    "- \"SKIP\": do not send.\n",
    "\n",
    "Respond with a SINGLE JSON object only:\n",
    "{{\"action\": \"ALLOW\"|\"COMPRESS\"|\"AGGREGATE\"|\"SKIP\", \"param\": number|null, \"size_bytes\": number|null}}\n",
    "Rules:\n",
    "- If action is \"AGGREGATE\", \"param\" must be one of {list(self.agg_ms_choices)} and \"size_bytes\" must be null.\n",
    "- If action is \"COMPRESS\", \"size_bytes\" must be {self.compress_size} and \"param\" must be null.\n",
    "- If action is \"ALLOW\", \"size_bytes\" must be {self.full_size} and \"param\" must be null.\n",
    "- If action is \"SKIP\", both \"param\" and \"size_bytes\" must be null.\n",
    "\"\"\"\n",
    "\n",
    "    def decide(self, *, delta, queue_depth, util=None):\n",
    "        # sanitize inputs\n",
    "        if not isfinite(delta) or delta < 0:\n",
    "            # push into the highest bin so the first send isn't skipped\n",
    "            delta = (self.bins_delta[-1] if self.bins_delta else 1.0) * 2.0\n",
    "        if queue_depth is None or queue_depth < 0:\n",
    "            queue_depth = 0\n",
    "\n",
    "        # bin features to limit prompt variety\n",
    "        dbin = self._bin(delta, self.bins_delta)\n",
    "        qbin = self._bin(queue_depth, self.bins_q)\n",
    "        cache_key = (dbin, qbin)\n",
    "\n",
    "        if self.use_cache and cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "\n",
    "        prompt = self._mk_prompt(delta, queue_depth, dbin, qbin)\n",
    "\n",
    "        # ---- call the (real or dummy) model ----\n",
    "        raw = self.call_model_fn(prompt)  # must return a JSON string\n",
    "\n",
    "        # ---- parse & validate ----\n",
    "        action, param, size_bytes = self._parse_and_validate(raw)\n",
    "\n",
    "        # cache\n",
    "        if self.use_cache:\n",
    "            self._cache[cache_key] = (action, param, size_bytes)\n",
    "        return action, param, size_bytes\n",
    "\n",
    "    def _parse_and_validate(self, raw):\n",
    "        # default safe fallback: ALLOW full size\n",
    "        fallback = (\"ALLOW\", None, self.full_size)\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(raw.strip())\n",
    "        except Exception:\n",
    "            return fallback\n",
    "\n",
    "        action = obj.get(\"action\")\n",
    "        param = obj.get(\"param\", None)\n",
    "        size  = obj.get(\"size_bytes\", None)\n",
    "\n",
    "        if action not in (\"ALLOW\", \"COMPRESS\", \"AGGREGATE\", \"SKIP\"):\n",
    "            return fallback\n",
    "\n",
    "        # enforce schema\n",
    "        if action == \"ALLOW\":\n",
    "            return (\"ALLOW\", None, self.full_size)\n",
    "        if action == \"COMPRESS\":\n",
    "            return (\"COMPRESS\", None, self.compress_size)\n",
    "        if action == \"AGGREGATE\":\n",
    "            if param in self.agg_ms_choices:\n",
    "                return (\"AGGREGATE\", param, None)\n",
    "            # snap to nearest allowed choice if model gave a number\n",
    "            if isinstance(param, (int, float)):\n",
    "                closest = min(self.agg_ms_choices, key=lambda x: abs(x - param))\n",
    "                return (\"AGGREGATE\", closest, None)\n",
    "            return fallback\n",
    "        if action == \"SKIP\":\n",
    "            return (\"SKIP\", None, None)\n",
    "\n",
    "        return fallback\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "class MockLLMPolicy:\n",
    "    \"\"\"\n",
    "    Stand-in for an LLM. Same interface as RulePolicy.\n",
    "    Returns (action, param, size_bytes).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 bins_delta=(0.02, 0.1, 0.5),\n",
    "                 q_hi=1,\n",
    "                 agg_ms_choices=(10,15,20)):\n",
    "        self.b0, self.b1, self.b2 = bins_delta\n",
    "        self.q_hi = q_hi\n",
    "        self.agg_ms_choices = agg_ms_choices\n",
    "\n",
    "    def decide(self, *, delta, queue_depth, util=None):\n",
    "        # congestion: aggregate if busy\n",
    "        if queue_depth >= self.q_hi:\n",
    "            return \"AGGREGATE\", self.agg_ms_choices[1], None\n",
    "        # improvement thresholds\n",
    "        if delta < self.b0:\n",
    "            return \"SKIP\", None, None\n",
    "        if delta < self.b1:\n",
    "            return \"COMPRESS\", None, 48\n",
    "        if delta < self.b2:\n",
    "            return \"AGGREGATE\", self.agg_ms_choices[0], None\n",
    "        return \"ALLOW\", None, 96\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#This is only to be able to use the LLM policy to test its connection before using the API\n",
    "\n",
    "def dummy_llm_call(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Cheap 'LLM' that reads queue bin / delta bin numbers from the prompt\n",
    "    and returns a reasonable JSON decision. Replace with a real API later.\n",
    "    \"\"\"\n",
    "    # Very crude parsing just for demonstration:\n",
    "    # Look for 'bin=' markers we put in the prompt\n",
    "    import re\n",
    "    m_d = re.search(r\"improvement_delta: .* \\(bin=(\\d+)\\)\", prompt)\n",
    "    m_q = re.search(r\"link_queue_depth: .* \\(bin=(\\d+)\\)\", prompt)\n",
    "    dbin = int(m_d.group(1)) if m_d else 0\n",
    "    qbin = int(m_q.group(1)) if m_q else 0\n",
    "\n",
    "    # Heuristic:\n",
    "    # - If queue bin is high, aggregate\n",
    "    # - Else if delta bin is tiny, skip\n",
    "    # - Else if delta is small, compress\n",
    "    # - Else allow\n",
    "    if qbin >= 2:\n",
    "        return '{\"action\":\"AGGREGATE\",\"param\":15,\"size_bytes\":null}'\n",
    "    if dbin <= 0:\n",
    "        return '{\"action\":\"SKIP\",\"param\":null,\"size_bytes\":null}'\n",
    "    if dbin == 1:\n",
    "        return '{\"action\":\"COMPRESS\",\"param\":null,\"size_bytes\":48}'\n",
    "    return '{\"action\":\"ALLOW\",\"param\":null,\"size_bytes\":96}'\n",
    "\n",
    "\n",
    "# -------------------- Controller (orchestrator) --------------------\n",
    "class Controller:\n",
    "    def __init__(self, env, graph, base_bps=3e5, base_prop_ms=2.0, policy=None):\n",
    "        self.env = env\n",
    "        self.links = {}\n",
    "        self.inflight = 0\n",
    "        self.policy = policy  # None => baseline\n",
    "        self.nodes = {u: Node(env, u, self, self.policy) for u in graph[\"nodes\"]}\n",
    "\n",
    "        # Heterogeneous links (bandwidth/latency vary per direction)\n",
    "        for (u, v, w) in graph[\"edges\"]:\n",
    "            bps_uv = random.uniform(0.5, 1.0) * base_bps\n",
    "            bps_vu = random.uniform(0.5, 1.0) * base_bps\n",
    "            prop_uv = random.uniform(0.2, 2.0) * base_prop_ms\n",
    "            prop_vu = random.uniform(0.2, 2.0) * base_prop_ms\n",
    "\n",
    "            l_uv = Link(self.env, u, v, bps_uv, prop_uv, capacity=64)\n",
    "            l_vu = Link(self.env, v, u, bps_vu, prop_vu, capacity=64)\n",
    "            self.links[(u, v)] = l_uv\n",
    "            self.links[(v, u)] = l_vu\n",
    "            self.nodes[u].add_neighbor(v, l_uv, w)\n",
    "            self.nodes[v].add_neighbor(u, l_vu, w)\n",
    "\n",
    "    def size_model(self, kind):  # bytes per message\n",
    "        return 96\n",
    "\n",
    "# -------------------- Graph + exact Dijkstra (for MAE) --------------------\n",
    "def make_grid(n_side=25, w=1.0, jitter=0.1):\n",
    "    nodes = [(i, j) for i in range(n_side) for j in range(n_side)]\n",
    "    idx = {nodes[k]: k for k in range(len(nodes))}\n",
    "    edges = []\n",
    "    for i in range(n_side):\n",
    "        for j in range(n_side):\n",
    "            u = idx[(i, j)]\n",
    "            if i + 1 < n_side:\n",
    "                v = idx[(i + 1, j)]\n",
    "                wij = random.uniform(w - jitter, w + jitter)\n",
    "                edges.append((u, v, wij))\n",
    "            if j + 1 < n_side:\n",
    "                v = idx[(i, j + 1)]\n",
    "                wij = random.uniform(w - jitter, w + jitter)\n",
    "                edges.append((u, v, wij))\n",
    "    return {\"nodes\": list(range(len(nodes))), \"edges\": edges}\n",
    "\n",
    "def dijkstra_cpu(graph, source):\n",
    "    adj = {u: [] for u in graph[\"nodes\"]}\n",
    "    for u, v, w in graph[\"edges\"]:\n",
    "        adj[u].append((v, w))\n",
    "        adj[v].append((u, w))\n",
    "    dist = {u: math.inf for u in graph[\"nodes\"]}\n",
    "    dist[source] = 0.0\n",
    "    pq = [(0.0, source)]\n",
    "    while pq:\n",
    "        d, u = heapq.heappop(pq)\n",
    "        if d != dist[u]:\n",
    "            continue\n",
    "        for v, w in adj[u]:\n",
    "            nd = d + w\n",
    "            if nd < dist[v]:\n",
    "                dist[v] = nd\n",
    "                heapq.heappush(pq, (nd, v))\n",
    "    return dist\n",
    "\n",
    "# -------------------- Optional: dynamic edge jitter during run --------------------\n",
    "def jitter_edges_periodically(ctrl, graph, period_ms=120, scale=0.02):\n",
    "    def loop():\n",
    "        while True:\n",
    "            for _ in range(10):  # tweak how many edges per tick\n",
    "                (u, v, w) = random.choice(graph[\"edges\"])\n",
    "                new_w = max(0.05, w * random.uniform(1 - scale, 1 + scale))\n",
    "                # update both directions' stored weights on nodes\n",
    "                if v in ctrl.nodes[u].neighbors:\n",
    "                    link, _old = ctrl.nodes[u].neighbors[v]\n",
    "                    ctrl.nodes[u].neighbors[v] = (link, new_w)\n",
    "                if u in ctrl.nodes[v].neighbors:\n",
    "                    link, _old = ctrl.nodes[v].neighbors[u]\n",
    "                    ctrl.nodes[v].neighbors[u] = (link, new_w)\n",
    "            yield ctrl.env.timeout(period_ms / 1000.0)\n",
    "    ctrl.env.process(loop())\n",
    "\n",
    "# -------------------- Run once (baseline or policy) --------------------\n",
    "def run_once(seed=0, policy_kind=\"rule\"):\n",
    "    random.seed(seed)\n",
    "    env = simpy.Environment()\n",
    "    G = make_grid(n_side=25, w=1.0, jitter=0.1)\n",
    "\n",
    "    if policy_kind == \"none\":\n",
    "        policy = None\n",
    "    elif policy_kind == \"rule\":\n",
    "        policy = RulePolicy(eps_small=0.05, eps_med=0.20, q_hi=1, agg_ms=20)\n",
    "    elif policy_kind == \"mockllm\":\n",
    "        policy = LLMPolicy(bins_delta=(0.02, 0.1, 0.5), q_hi=1, agg_ms_choices=(10,15,20))\n",
    "    elif policy_kind == \"llm\":\n",
    "        policy = LLMPolicy(call_model_fn=dummy_llm_call,\n",
    "                           bins_delta=(0.02, 0.1, 0.5, 1.0),\n",
    "                           bins_q=(0, 1, 2, 4, 8),\n",
    "                           agg_ms_choices=(5,10,20),\n",
    "                           compress_size=48,\n",
    "                           full_size=96,\n",
    "                           use_cache=True)\n",
    "    else:\n",
    "        raise ValueError(\"unknown policy_kind\")\n",
    "    ctrl = Controller(env, G, base_bps=8e5, base_prop_ms=1.0, policy=policy)\n",
    "\n",
    "    # Multiple staggered sources -> overlapping waves\n",
    "    N = len(G[\"nodes\"])\n",
    "    sources = [0, 150, 300, 450, 600] \n",
    "    def start_source_later(s, delay_ms):\n",
    "        yield env.timeout(delay_ms / 1000.0)\n",
    "        ctrl.nodes[s].init_source(s)\n",
    "    for idx, s in enumerate(sources):\n",
    "        env.process(start_source_later(s, delay_ms=idx * 25))  # 0, 25, 50 ms\n",
    "\n",
    "    # if use_dynamic_jitter:\n",
    "    #     jitter_edges_periodically(ctrl, G, period_ms=120, scale=0.02)\n",
    "\n",
    "    # stop when quiescent or time cap reached\n",
    "    def stopper(timeout_s=15.0, quiet_ms=80):\n",
    "        quiet = 0.0\n",
    "        while env.now < timeout_s:\n",
    "            yield env.timeout(0.005)\n",
    "            if ctrl.inflight == 0:\n",
    "                quiet += 0.005\n",
    "                if quiet >= (quiet_ms / 1000.0):\n",
    "                    break\n",
    "            else:\n",
    "                quiet = 0.0\n",
    "    env.process(stopper())\n",
    "    env.run()\n",
    "\n",
    "    # Metrics\n",
    "    total_bytes = sum(l.bytes_sent for l in ctrl.links.values())\n",
    "    total_msgs  = sum(l.messages_sent for l in ctrl.links.values())\n",
    "    max_q = max((l.max_q_depth for l in ctrl.links.values()), default=0)\n",
    "\n",
    "    # Policy action summary (if enabled)\n",
    "    action_totals = {}\n",
    "    if ctrl.policy is not None:\n",
    "        agg = defaultdict(int)\n",
    "        for node in ctrl.nodes.values():\n",
    "            for k, v in getattr(node, \"action_counts\", {}).items():\n",
    "                agg[k] += v\n",
    "        action_totals = dict(agg)\n",
    "        print(\"Action summary:\", action_totals)\n",
    "        print(\"Max queue depth observed:\", max_q)\n",
    "\n",
    "    # Accuracy vs exact (per source), report average MAE\n",
    "    maes = []\n",
    "    for s in sources:\n",
    "        exact = dijkstra_cpu(G, s)\n",
    "        approx = {u: ctrl.nodes[u].dist.get(s, math.inf) for u in G[\"nodes\"]}\n",
    "        mae = sum(abs(approx[u] - exact[u]) for u in G[\"nodes\"]) / len(G[\"nodes\"])\n",
    "        maes.append(mae)\n",
    "    avg_mae = sum(maes) / len(maes)\n",
    "\n",
    "    return {\n",
    "        \"bytes\": total_bytes,\n",
    "        \"msgs\": total_msgs,\n",
    "        \"time\": env.now,\n",
    "        \"avg_mae\": avg_mae,\n",
    "        \"max_q\": max_q,\n",
    "        \"actions\": action_totals\n",
    "    }\n",
    "\n",
    "# -------------------- Main: compare baseline vs policy --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    baseline = run_once(policy_kind=\"none\")\n",
    "    print(\"Baseline (no policy):\", {k:v for k,v in baseline.items() if k!='actions'})\n",
    "\n",
    "    ruled = run_once(policy_kind=\"rule\")\n",
    "    print(\"RulePolicy:\", {k:v for k,v in ruled.items() if k!='actions'})\n",
    "\n",
    "    mocked   = run_once(policy_kind=\"llm\")\n",
    "    print(\"LLMPolicy:\", {k:v for k,v in mocked.items() if k!='actions'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37298c75-7e62-455c-8251-54ed659f18f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
