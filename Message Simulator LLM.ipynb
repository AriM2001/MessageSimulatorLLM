{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6378b3f2-b056-4fce-9285-1531d3c36678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the notebook so its functions exist in the current namespace (not as a module)\n",
    "%run adapters.ipynb\n",
    "%run providers.ipynb\n",
    "\n",
    "# now you can just call make_call_model_fn(...) directly since it's defined in the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c47fae-c527-4863-b2c3-c29f384c3808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (no policy): {'bytes': 29750496, 'msgs': 309901, 'time': 1.5149999999999897, 'avg_mae': 0.0, 'max_q': 65}\n",
      "latency: 13.93 s\n",
      "reply: ```json\n",
      "{\n",
      "  \"ok\": true\n",
      "}\n",
      "```\n",
      "\n",
      "models=[Model(model='phi3:mini', modified_at=datetime.datetime(2025, 10, 31, 16, 53, 29, 524095, tzinfo=TzInfo(-25200)), digest='4f222292793889a9a40a020799cfd28d53f3e01af25d48e06c5e708610fc47e9', size=2176178913, details=ModelDetails(parent_model='', format='gguf', family='phi3', families=['phi3'], parameter_size='3.8B', quantization_level='Q4_0'))]\n",
      "Action summary: {'ALLOW': 30674, 'COMPRESS': 59225, 'AGGREGATE': 15033, 'SKIP': 5621}\n",
      "Max queue depth observed: 3\n",
      "RulePolicy: {'bytes': 6539280, 'msgs': 97730, 'time': 0.3500000000000002, 'avg_mae': 0.009605144268427145, 'max_q': 3}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 466\u001b[0m, in \u001b[0;36mrun_once.<locals>.start_source_later\u001b[1;34m(s, delay_ms)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m env\u001b[38;5;241m.\u001b[39mtimeout(delay_ms \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000.0\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m \u001b[43mctrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 90\u001b[0m, in \u001b[0;36mNode.init_source\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v,(link,w) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighbors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 110\u001b[0m, in \u001b[0;36mNode._maybe_send\u001b[1;34m(self, v, s, d)\u001b[0m\n\u001b[0;32m    108\u001b[0m queue_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(link\u001b[38;5;241m.\u001b[39mq\u001b[38;5;241m.\u001b[39mitems)\n\u001b[1;32m--> 110\u001b[0m action, param, size_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# action, param, size_bytes = self.policy.decide(\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m#     delta=delta, queue_depth=queue_depth, util=None\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 244\u001b[0m, in \u001b[0;36mLLMPolicy.decide\u001b[1;34m(self, delta, queue_depth, util)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# ---- call the (real or dummy) model ----\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# must return a JSON string\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# ---- parse & validate ----\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Distributed Systems\\adapters.py:108\u001b[0m, in \u001b[0;36mmake_call_model_fn.<locals>._call\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# call provider\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mllm_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17492\\4059395783.py:31\u001b[0m, in \u001b[0;36mollama_json\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# You can nudge shorter outputs if desired:\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_predict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Typical causes: server not running or model not pulled\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:351\u001b[0m, in \u001b[0;36mClient.chat\u001b[1;34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03mCreate a chat response using the requested model.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03mReturns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m  \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:189\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:129\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m   r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m   r\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    824\u001b[0m )\n\u001b[1;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 542\u001b[0m\n\u001b[0;32m    539\u001b[0m ruled \u001b[38;5;241m=\u001b[39m run_once(policy_kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRulePolicy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m ruled\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m--> 542\u001b[0m mocked   \u001b[38;5;241m=\u001b[39m \u001b[43mrun_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_kind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLMPolicy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m mocked\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "Cell \u001b[1;32mIn[5], line 485\u001b[0m, in \u001b[0;36mrun_once\u001b[1;34m(seed, policy_kind)\u001b[0m\n\u001b[0;32m    483\u001b[0m             quiet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    484\u001b[0m env\u001b[38;5;241m.\u001b[39mprocess(stopper())\n\u001b[1;32m--> 485\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# Metrics\u001b[39;00m\n\u001b[0;32m    488\u001b[0m total_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(l\u001b[38;5;241m.\u001b[39mbytes_sent \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m ctrl\u001b[38;5;241m.\u001b[39mlinks\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simpy\\core.py:246\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, until)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StopSimulation \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# == until.value\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\simpy\\core.py:204\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(event\u001b[38;5;241m.\u001b[39m_value)(\u001b[38;5;241m*\u001b[39mevent\u001b[38;5;241m.\u001b[39m_value\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m    203\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# message_opt_sim.py\n",
    "import json\n",
    "import os\n",
    "import simpy, math, random, heapq, hashlib\n",
    "import ollama\n",
    "from adapters import make_call_model_fn\n",
    "from providers import openai_json, anthropic_json, vllm_http_json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Callable\n",
    "from collections import defaultdict\n",
    "from math import isfinite\n",
    "\n",
    "BITS_PER_BYTE = 8\n",
    "\n",
    "os.environ[\"OLLAMA_MODEL\"] = \"phi3:mini\"   # \"llama3.1\" was a previous model but it ran too slow \"qwen2.5:7b-instruct\", etc.\n",
    "\n",
    "# -------------------- Link (network channel) --------------------\n",
    "class Link:\n",
    "    def __init__(self, env, u, v, bandwidth_bps, prop_delay_ms, capacity=32):   #udpated smaller queue depth\n",
    "        self.env = env\n",
    "        self.u, self.v = u, v\n",
    "        self.bps = bandwidth_bps\n",
    "        self.prop = prop_delay_ms / 1000.0\n",
    "        self.q = simpy.Store(env, capacity=capacity)   # finite queue -> backpressure\n",
    "        self.bytes_sent = 0\n",
    "        self.messages_sent = 0\n",
    "        self.max_q_depth = 0\n",
    "        env.process(self.run())\n",
    "\n",
    "    def send(self, size_bytes, payload):\n",
    "        # put() blocks if queue is full -> natural backpressure\n",
    "        self.bytes_sent += size_bytes\n",
    "        self.messages_sent += 1\n",
    "        self.max_q_depth = max(self.max_q_depth, len(self.q.items) + 1)\n",
    "        return self.q.put((size_bytes, payload))\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            size_bytes, payload = (yield self.q.get())\n",
    "            ser = (size_bytes * BITS_PER_BYTE) / self.bps\n",
    "            yield self.env.timeout(ser + self.prop)\n",
    "            payload[\"dst\"].inbox.put(payload)\n",
    "\n",
    "# -------------------- Queue-aware Rule Policy --------------------\n",
    "class RulePolicy:\n",
    "    \"\"\"\n",
    "    Realistic queue-aware policy:\n",
    "      - If tiny improvement and link is busy -> SKIP (shed low-value load)\n",
    "      - If queue has backlog -> AGGREGATE (batch for a short window)\n",
    "      - If small improvement -> COMPRESS (smaller payload)\n",
    "      - Else -> ALLOW\n",
    "    \"\"\"\n",
    "    def __init__(self, eps_small=0.05, eps_med=0.20, q_hi=1, agg_ms=20):\n",
    "        self.eps_small = eps_small\n",
    "        self.eps_med = eps_med\n",
    "        self.q_hi = q_hi\n",
    "        self.agg_ms = agg_ms\n",
    "\n",
    "    def decide(self, *, delta, queue_depth, util=None):\n",
    "        if delta < self.eps_small and queue_depth > 0:\n",
    "            return \"SKIP\", None, None\n",
    "        if queue_depth >= self.q_hi:\n",
    "            return \"AGGREGATE\", self.agg_ms, None\n",
    "        if delta < self.eps_med:\n",
    "            return \"COMPRESS\", None, 48  # bytes\n",
    "        return \"ALLOW\", None, 96         # bytes\n",
    "\n",
    "# -------------------- Node (distributed process) --------------------\n",
    "class Node:\n",
    "    def __init__(self, env, node_id, controller, policy):\n",
    "        self.env = env\n",
    "        self.id = node_id\n",
    "        self.ctrl = controller\n",
    "        self.policy = policy                    # may be None for baseline\n",
    "        self.neighbors = {}                     # v -> (link, weight)\n",
    "        self.inbox = simpy.Store(env)\n",
    "        self.dist = defaultdict(lambda: math.inf)\n",
    "        self.last_sent = defaultdict(lambda: math.inf)  # best value last sent per (v,s)\n",
    "        self.pending = {}                       # aggregation buffers\n",
    "        self.action_counts = defaultdict(int)   # instrumentation\n",
    "        env.process(self.recv_loop())\n",
    "\n",
    "    def add_neighbor(self, v, link, w):\n",
    "        self.neighbors[v] = (link, w)\n",
    "\n",
    "    def init_source(self, s):\n",
    "        if self.id == s:\n",
    "            self.dist[s] = 0.0\n",
    "            for v,(link,w) in self.neighbors.items():\n",
    "                self._maybe_send(v, s, self.dist[s] + w)\n",
    "\n",
    "    def _enqueue_send(self, link, payload, size_bytes):\n",
    "        self.ctrl.inflight += 1\n",
    "        link.send(size_bytes, payload)\n",
    "\n",
    "    def _maybe_send(self, v, s, d):\n",
    "        link,_ = self.neighbors[v]\n",
    "\n",
    "        # Baseline: always send full message\n",
    "        if self.policy is None:\n",
    "            msg = {\"kind\":\"RELAX\",\"src\":self,\"dst\":self.ctrl.nodes[v],\"s\":s,\"d\":d}\n",
    "            self.last_sent[(v,s)] = d\n",
    "            self._enqueue_send(link, msg, self.ctrl.size_model(\"RELAX\"))\n",
    "            return\n",
    "\n",
    "        old = self.last_sent[(v,s)]\n",
    "        delta = abs(d - old)\n",
    "        queue_depth = len(link.q.items)\n",
    "\n",
    "        action, param, size_bytes = self.policy.decide(\n",
    "        delta=delta, queue_depth=queue_depth, util=None\n",
    "        )\n",
    "        # action, param, size_bytes = self.policy.decide(\n",
    "        #     delta=delta, queue_depth=queue_depth, util=None\n",
    "        # )\n",
    "        \n",
    "        self.action_counts[action] += 1\n",
    "        if action == \"SKIP\":\n",
    "            return\n",
    "\n",
    "        if action == \"AGGREGATE\":\n",
    "            key = (v,s)\n",
    "            self.pending[key] = d\n",
    "            if (\"timer\", key) not in self.pending:\n",
    "                self.pending[(\"timer\", key)] = True\n",
    "                self.env.process(self._aggregate_after(param, v, s, link))\n",
    "            return\n",
    "\n",
    "        # ALLOW/COMPRESS -> send immediately\n",
    "        send_size = size_bytes if size_bytes is not None else self.ctrl.size_model(\"RELAX\")\n",
    "        msg = {\"kind\":\"RELAX\",\"src\":self,\"dst\":self.ctrl.nodes[v],\"s\":s,\"d\":d}\n",
    "        self.last_sent[(v,s)] = d\n",
    "        self._enqueue_send(link, msg, send_size)\n",
    "\n",
    "    def _aggregate_after(self, delay_ms, v, s, link):\n",
    "        yield self.env.timeout(delay_ms / 1000.0)\n",
    "        key = (v,s)\n",
    "        if key in self.pending:\n",
    "            d = self.pending.pop(key)\n",
    "            _ = self.pending.pop((\"timer\", key), None)\n",
    "            send_size = self.ctrl.size_model(\"RELAX\")\n",
    "            msg = {\"kind\":\"RELAX\",\"src\":self,\"dst\":self.ctrl.nodes[v],\"s\":s,\"d\":d}\n",
    "            self.last_sent[(v,s)] = d\n",
    "            self._enqueue_send(link, msg, send_size)\n",
    "        else:\n",
    "            _ = self.pending.pop((\"timer\", key), None)\n",
    "\n",
    "    def recv_loop(self):\n",
    "        while True:\n",
    "            msg = (yield self.inbox.get())\n",
    "            self.ctrl.inflight -= 1\n",
    "            if msg[\"kind\"] == \"RELAX\":\n",
    "                s, d = msg[\"s\"], msg[\"d\"]\n",
    "                if d < self.dist[s]:\n",
    "                    self.dist[s] = d\n",
    "                    for v,(link,w) in self.neighbors.items():\n",
    "                        self._maybe_send(v, s, self.dist[s] + w)\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "class LLMPolicy:\n",
    "    \"\"\"\n",
    "    Real-LLM policy stub:\n",
    "    - Bins features (delta, queue_depth) to reduce distinct prompts.\n",
    "    - Calls `call_model_fn(prompt: str) -> str` that returns a JSON decision.\n",
    "    - Returns (action, param, size_bytes) like other policies.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 call_model_fn,\n",
    "                 bins_delta=(0.02, 0.1, 0.5, 1.0),\n",
    "                 bins_q=(0, 1, 2, 4, 8),\n",
    "                 agg_ms_choices=(5, 10, 20),\n",
    "                 compress_size=48,\n",
    "                 full_size=96,\n",
    "                 use_cache=True):\n",
    "        self.call_model_fn = call_model_fn\n",
    "        self.bins_delta = tuple(sorted(bins_delta))\n",
    "        self.bins_q = tuple(sorted(bins_q))\n",
    "        self.agg_ms_choices = agg_ms_choices\n",
    "        self.compress_size = compress_size\n",
    "        self.full_size = full_size\n",
    "        self.use_cache = use_cache\n",
    "        self._cache = {}  # (delta_bin, q_bin) -> (action, param, size_bytes)\n",
    "        \n",
    "    # ---- helpers ----\n",
    "    def _bin(self, x, edges):\n",
    "        # place x into a discrete bin index: 0..len(edges)\n",
    "        for i, e in enumerate(edges):\n",
    "            if x < e:\n",
    "                return i\n",
    "        return len(edges)\n",
    "\n",
    "    def _mk_prompt(self, delta, qdepth, dbin, qbin):\n",
    "        # Keep the prompt small and deterministic so caching works well.\n",
    "        return f\"\"\"\n",
    "You are controlling message sending in a distributed shortest-path simulation.\n",
    "\n",
    "Inputs:\n",
    "- improvement_delta: {delta:.6f} (bin={dbin})\n",
    "- link_queue_depth: {qdepth} (bin={qbin})\n",
    "\n",
    "Goal:\n",
    "- Minimize total bytes and messages.\n",
    "- Keep accuracy high (prefer small error).\n",
    "- Avoid adding much latency; only aggregate briefly if helpful.\n",
    "\n",
    "Action space (choose exactly one):\n",
    "- \"ALLOW\": send now with full size {self.full_size}.\n",
    "- \"COMPRESS\": send now with smaller size {self.compress_size}.\n",
    "- \"AGGREGATE\": delay briefly to coalesce; choose param in ms from {list(self.agg_ms_choices)}.\n",
    "- \"SKIP\": do not send.\n",
    "\n",
    "Respond with a SINGLE JSON object only:\n",
    "{{\"action\": \"ALLOW\"|\"COMPRESS\"|\"AGGREGATE\"|\"SKIP\", \"param\": number|null, \"size_bytes\": number|null}}\n",
    "Rules:\n",
    "- If action is \"AGGREGATE\", \"param\" must be one of {list(self.agg_ms_choices)} and \"size_bytes\" must be null.\n",
    "- If action is \"COMPRESS\", \"size_bytes\" must be {self.compress_size} and \"param\" must be null.\n",
    "- If action is \"ALLOW\", \"size_bytes\" must be {self.full_size} and \"param\" must be null.\n",
    "- If action is \"SKIP\", both \"param\" and \"size_bytes\" must be null.\n",
    "\"\"\"\n",
    "\n",
    "    def decide(self, *, delta, queue_depth, util=None):\n",
    "        # sanitize inputs\n",
    "        if not isfinite(delta) or delta < 0:\n",
    "            # push into the highest bin so the first send isn't skipped\n",
    "            delta = (self.bins_delta[-1] if self.bins_delta else 1.0) * 2.0\n",
    "        if queue_depth is None or queue_depth < 0:\n",
    "            queue_depth = 0\n",
    "\n",
    "        # bin features to limit prompt variety\n",
    "        dbin = self._bin(delta, self.bins_delta)\n",
    "        qbin = self._bin(queue_depth, self.bins_q)\n",
    "        cache_key = (dbin, qbin)\n",
    "\n",
    "        if self.use_cache and cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "\n",
    "        prompt = self._mk_prompt(delta, queue_depth, dbin, qbin)\n",
    "\n",
    "        # ---- call the (real or dummy) model ----\n",
    "        raw = self.call_model_fn(prompt)  # must return a JSON string\n",
    "\n",
    "        # ---- parse & validate ----\n",
    "        action, param, size_bytes = self._parse_and_validate(raw)\n",
    "\n",
    "        # cache\n",
    "        if self.use_cache:\n",
    "            self._cache[cache_key] = (action, param, size_bytes)\n",
    "        return action, param, size_bytes\n",
    "\n",
    "    def _parse_and_validate(self, raw):\n",
    "        # default safe fallback: ALLOW full size\n",
    "        fallback = (\"ALLOW\", None, self.full_size)\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(raw.strip())\n",
    "        except Exception:\n",
    "            return fallback\n",
    "\n",
    "        action = obj.get(\"action\")\n",
    "        param = obj.get(\"param\", None)\n",
    "        size  = obj.get(\"size_bytes\", None)\n",
    "\n",
    "        if action not in (\"ALLOW\", \"COMPRESS\", \"AGGREGATE\", \"SKIP\"):\n",
    "            return fallback\n",
    "\n",
    "        # enforce schema\n",
    "        if action == \"ALLOW\":\n",
    "            return (\"ALLOW\", None, self.full_size)\n",
    "        if action == \"COMPRESS\":\n",
    "            return (\"COMPRESS\", None, self.compress_size)\n",
    "        if action == \"AGGREGATE\":\n",
    "            if param in self.agg_ms_choices:\n",
    "                return (\"AGGREGATE\", param, None)\n",
    "            # snap to nearest allowed choice if model gave a number\n",
    "            if isinstance(param, (int, float)):\n",
    "                closest = min(self.agg_ms_choices, key=lambda x: abs(x - param))\n",
    "                return (\"AGGREGATE\", closest, None)\n",
    "            return fallback\n",
    "        if action == \"SKIP\":\n",
    "            return (\"SKIP\", None, None)\n",
    "\n",
    "        return fallback\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "class MockLLMPolicy:\n",
    "    \"\"\"\n",
    "    Stand-in for an LLM. Same interface as RulePolicy.\n",
    "    Returns (action, param, size_bytes).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 bins_delta=(0.02, 0.1, 0.5),\n",
    "                 q_hi=1,\n",
    "                 agg_ms_choices=(10,15,20)):\n",
    "        self.b0, self.b1, self.b2 = bins_delta\n",
    "        self.q_hi = q_hi\n",
    "        self.agg_ms_choices = agg_ms_choices\n",
    "\n",
    "    def decide(self, *, delta, queue_depth, util=None):\n",
    "        # congestion: aggregate if busy\n",
    "        if queue_depth >= self.q_hi:\n",
    "            return \"AGGREGATE\", self.agg_ms_choices[1], None\n",
    "        # improvement thresholds\n",
    "        if delta < self.b0:\n",
    "            return \"SKIP\", None, None\n",
    "        if delta < self.b1:\n",
    "            return \"COMPRESS\", None, 48\n",
    "        if delta < self.b2:\n",
    "            return \"AGGREGATE\", self.agg_ms_choices[0], None\n",
    "        return \"ALLOW\", None, 96\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#This is only to be able to use the LLM policy to test its connection before using the API\n",
    "\n",
    "def dummy_llm_call(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Cheap 'LLM' that reads queue bin / delta bin numbers from the prompt\n",
    "    and returns a reasonable JSON decision. Replace with a real API later.\n",
    "    \"\"\"\n",
    "    # Very crude parsing just for demonstration:\n",
    "    # Look for 'bin=' markers we put in the prompt\n",
    "    import re\n",
    "    m_d = re.search(r\"improvement_delta: .* \\(bin=(\\d+)\\)\", prompt)\n",
    "    m_q = re.search(r\"link_queue_depth: .* \\(bin=(\\d+)\\)\", prompt)\n",
    "    dbin = int(m_d.group(1)) if m_d else 0\n",
    "    qbin = int(m_q.group(1)) if m_q else 0\n",
    "\n",
    "    # Heuristic:\n",
    "    # - If queue bin is high, aggregate\n",
    "    # - Else if delta bin is tiny, skip\n",
    "    # - Else if delta is small, compress\n",
    "    # - Else allow\n",
    "    if qbin >= 2:\n",
    "        return '{\"action\":\"AGGREGATE\",\"param\":15,\"size_bytes\":null}'\n",
    "    if dbin <= 0:\n",
    "        return '{\"action\":\"SKIP\",\"param\":null,\"size_bytes\":null}'\n",
    "    if dbin == 1:\n",
    "        return '{\"action\":\"COMPRESS\",\"param\":null,\"size_bytes\":48}'\n",
    "    return '{\"action\":\"ALLOW\",\"param\":null,\"size_bytes\":96}'\n",
    "\n",
    "\n",
    "# -------------------- Controller (orchestrator) --------------------\n",
    "class Controller:\n",
    "    def __init__(self, env, graph, base_bps=3e5, base_prop_ms=2.0, policy=None):\n",
    "        self.env = env\n",
    "        self.links = {}\n",
    "        self.inflight = 0\n",
    "        self.policy = policy  # None => baseline\n",
    "        self.nodes = {u: Node(env, u, self, self.policy) for u in graph[\"nodes\"]}\n",
    "\n",
    "        # Heterogeneous links (bandwidth/latency vary per direction)\n",
    "        for (u, v, w) in graph[\"edges\"]:\n",
    "            bps_uv = random.uniform(0.5, 1.0) * base_bps\n",
    "            bps_vu = random.uniform(0.5, 1.0) * base_bps\n",
    "            prop_uv = random.uniform(0.2, 2.0) * base_prop_ms\n",
    "            prop_vu = random.uniform(0.2, 2.0) * base_prop_ms\n",
    "\n",
    "            l_uv = Link(self.env, u, v, bps_uv, prop_uv, capacity=64)\n",
    "            l_vu = Link(self.env, v, u, bps_vu, prop_vu, capacity=64)\n",
    "            self.links[(u, v)] = l_uv\n",
    "            self.links[(v, u)] = l_vu\n",
    "            self.nodes[u].add_neighbor(v, l_uv, w)\n",
    "            self.nodes[v].add_neighbor(u, l_vu, w)\n",
    "\n",
    "    def size_model(self, kind):  # bytes per message\n",
    "        return 96\n",
    "\n",
    "# -------------------- Graph + exact Dijkstra (for MAE) --------------------\n",
    "def make_grid(n_side=25, w=1.0, jitter=0.1):\n",
    "    nodes = [(i, j) for i in range(n_side) for j in range(n_side)]\n",
    "    idx = {nodes[k]: k for k in range(len(nodes))}\n",
    "    edges = []\n",
    "    for i in range(n_side):\n",
    "        for j in range(n_side):\n",
    "            u = idx[(i, j)]\n",
    "            if i + 1 < n_side:\n",
    "                v = idx[(i + 1, j)]\n",
    "                wij = random.uniform(w - jitter, w + jitter)\n",
    "                edges.append((u, v, wij))\n",
    "            if j + 1 < n_side:\n",
    "                v = idx[(i, j + 1)]\n",
    "                wij = random.uniform(w - jitter, w + jitter)\n",
    "                edges.append((u, v, wij))\n",
    "    return {\"nodes\": list(range(len(nodes))), \"edges\": edges}\n",
    "\n",
    "def dijkstra_cpu(graph, source):\n",
    "    adj = {u: [] for u in graph[\"nodes\"]}\n",
    "    for u, v, w in graph[\"edges\"]:\n",
    "        adj[u].append((v, w))\n",
    "        adj[v].append((u, w))\n",
    "    dist = {u: math.inf for u in graph[\"nodes\"]}\n",
    "    dist[source] = 0.0\n",
    "    pq = [(0.0, source)]\n",
    "    while pq:\n",
    "        d, u = heapq.heappop(pq)\n",
    "        if d != dist[u]:\n",
    "            continue\n",
    "        for v, w in adj[u]:\n",
    "            nd = d + w\n",
    "            if nd < dist[v]:\n",
    "                dist[v] = nd\n",
    "                heapq.heappush(pq, (nd, v))\n",
    "    return dist\n",
    "\n",
    "# -------------------- Optional: dynamic edge jitter during run --------------------\n",
    "def jitter_edges_periodically(ctrl, graph, period_ms=120, scale=0.02):\n",
    "    def loop():\n",
    "        while True:\n",
    "            for _ in range(10):  # tweak how many edges per tick\n",
    "                (u, v, w) = random.choice(graph[\"edges\"])\n",
    "                new_w = max(0.05, w * random.uniform(1 - scale, 1 + scale))\n",
    "                # update both directions' stored weights on nodes\n",
    "                if v in ctrl.nodes[u].neighbors:\n",
    "                    link, _old = ctrl.nodes[u].neighbors[v]\n",
    "                    ctrl.nodes[u].neighbors[v] = (link, new_w)\n",
    "                if u in ctrl.nodes[v].neighbors:\n",
    "                    link, _old = ctrl.nodes[v].neighbors[u]\n",
    "                    ctrl.nodes[v].neighbors[u] = (link, new_w)\n",
    "            yield ctrl.env.timeout(period_ms / 1000.0)\n",
    "    ctrl.env.process(loop())\n",
    "\n",
    "# -------------------- Run once (baseline or policy) --------------------\n",
    "\n",
    "def run_once(seed=0, policy_kind=\"rule\"):\n",
    "    random.seed(seed)\n",
    "    env = simpy.Environment()\n",
    "    G = make_grid(n_side=25, w=1.0, jitter=0.1)\n",
    "\n",
    "    if policy_kind == \"none\":\n",
    "        policy = None\n",
    "    elif policy_kind == \"rule\":\n",
    "        policy = RulePolicy(eps_small=0.05, eps_med=0.20, q_hi=1, agg_ms=20)\n",
    "    elif policy_kind == \"mockllm\":\n",
    "        policy = LLMPolicy(bins_delta=(0.02, 0.1, 0.5), q_hi=1, agg_ms_choices=(10,15,20))\n",
    "    elif policy_kind == \"llm\":\n",
    "        policy = LLMPolicy(\n",
    "            call_model_fn = make_call_model_fn(\n",
    "                llm_call = ollama_json,               # This is where the LLM is chosen\n",
    "                full_size = 96,\n",
    "                compress_size = 48,\n",
    "                agg_ms_choices = (5,10,20),\n",
    "                rps = 5.0, burst = 10,\n",
    "            ),\n",
    "            bins_delta = (0.01, 0.05, 0.2, 0.8),\n",
    "            bins_q = (0, 1, 2, 4, 8),\n",
    "            agg_ms_choices = (5,10,20),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"unknown policy_kind\")\n",
    "    ctrl = Controller(env, G, base_bps=8e5, base_prop_ms=1.0, policy=policy)\n",
    "\n",
    "    # Multiple staggered sources -> overlapping waves\n",
    "    N = len(G[\"nodes\"])\n",
    "    sources = [0, 150, 300, 450, 600] \n",
    "    def start_source_later(s, delay_ms):\n",
    "        yield env.timeout(delay_ms / 1000.0)\n",
    "        ctrl.nodes[s].init_source(s)\n",
    "    for idx, s in enumerate(sources):\n",
    "        env.process(start_source_later(s, delay_ms=idx * 25))  # 0, 25, 50 ms\n",
    "\n",
    "    # if use_dynamic_jitter:\n",
    "    #     jitter_edges_periodically(ctrl, G, period_ms=120, scale=0.02)\n",
    "\n",
    "    # stop when quiescent or time cap reached\n",
    "    def stopper(timeout_s=15.0, quiet_ms=80):\n",
    "        quiet = 0.0\n",
    "        while env.now < timeout_s:\n",
    "            yield env.timeout(0.005)\n",
    "            if ctrl.inflight == 0:\n",
    "                quiet += 0.005\n",
    "                if quiet >= (quiet_ms / 1000.0):\n",
    "                    break\n",
    "            else:\n",
    "                quiet = 0.0\n",
    "    env.process(stopper())\n",
    "    env.run()\n",
    "\n",
    "    # Metrics\n",
    "    total_bytes = sum(l.bytes_sent for l in ctrl.links.values())\n",
    "    total_msgs  = sum(l.messages_sent for l in ctrl.links.values())\n",
    "    max_q = max((l.max_q_depth for l in ctrl.links.values()), default=0)\n",
    "\n",
    "    # Policy action summary (if enabled)\n",
    "    action_totals = {}\n",
    "    if ctrl.policy is not None:\n",
    "        agg = defaultdict(int)\n",
    "        for node in ctrl.nodes.values():\n",
    "            for k, v in getattr(node, \"action_counts\", {}).items():\n",
    "                agg[k] += v\n",
    "        action_totals = dict(agg)\n",
    "        print(\"Action summary:\", action_totals)\n",
    "        print(\"Max queue depth observed:\", max_q)\n",
    "\n",
    "    # Accuracy vs exact (per source), report average MAE\n",
    "    maes = []\n",
    "    for s in sources:\n",
    "        exact = dijkstra_cpu(G, s)\n",
    "        approx = {u: ctrl.nodes[u].dist.get(s, math.inf) for u in G[\"nodes\"]}\n",
    "        mae = sum(abs(approx[u] - exact[u]) for u in G[\"nodes\"]) / len(G[\"nodes\"])\n",
    "        maes.append(mae)\n",
    "    avg_mae = sum(maes) / len(maes)\n",
    "\n",
    "    return {\n",
    "        \"bytes\": total_bytes,\n",
    "        \"msgs\": total_msgs,\n",
    "        \"time\": env.now,\n",
    "        \"avg_mae\": avg_mae,\n",
    "        \"max_q\": max_q,\n",
    "        \"actions\": action_totals\n",
    "    }\n",
    "\n",
    "\n",
    "#ADDED STUFF TO CHECK\n",
    "\n",
    "\n",
    "####ADDED MORE STUFF TO CJECK\n",
    "# -------------------- Main: compare baseline vs policy --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    baseline = run_once(policy_kind=\"none\")\n",
    "    print(\"Baseline (no policy):\", {k:v for k,v in baseline.items() if k!='actions'})\n",
    "\n",
    "    import time\n",
    "    t0=time.perf_counter()\n",
    "    r = ollama.chat(model=\"phi3:mini\", messages=[{\"role\":\"user\",\"content\":'return only {\"ok\":true}'}],\n",
    "                    options={\"temperature\":0.0, \"num_predict\":16})\n",
    "    print(\"latency:\", round(time.perf_counter()-t0,2), \"s\")\n",
    "    print(\"reply:\", r[\"message\"][\"content\"])\n",
    "    print(ollama.list())\n",
    "    \n",
    "    ruled = run_once(policy_kind=\"rule\")\n",
    "    print(\"RulePolicy:\", {k:v for k,v in ruled.items() if k!='actions'})\n",
    "\n",
    "    mocked   = run_once(policy_kind=\"llm\")\n",
    "    print(\"LLMPolicy:\", {k:v for k,v in mocked.items() if k!='actions'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351f30c-09ca-44a8-b9b1-f297449fd49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07011752-4400-4f4f-bbba-8621979d8eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
