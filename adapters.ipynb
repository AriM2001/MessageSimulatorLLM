{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ec4f55-7b8a-4dc9-b43f-d7aca48b0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapters.py\n",
    "import hashlib, json, os, time, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Callable\n",
    "\n",
    "@dataclass\n",
    "class Decision:\n",
    "    action: str               # \"ALLOW\" | \"COMPRESS\" | \"AGGREGATE\" | \"SKIP\"\n",
    "    param: Optional[int]      # ms for AGGREGATE else None\n",
    "    size_bytes: Optional[int] # bytes for {ALLOW,COMPRESS} else None\n",
    "\n",
    "VALID_ACTIONS = {\"ALLOW\",\"COMPRESS\",\"AGGREGATE\",\"SKIP\"}\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, max_items=10000):\n",
    "        self.store = {}\n",
    "        self.order = []\n",
    "        self.max_items = max_items\n",
    "\n",
    "    def get(self, k):\n",
    "        v = self.store.get(k)\n",
    "        if v is not None:\n",
    "            # simple recency bump\n",
    "            self.order.remove(k); self.order.append(k)\n",
    "        return v\n",
    "\n",
    "    def put(self, k, v):\n",
    "        if k in self.store:\n",
    "            self.order.remove(k)\n",
    "        self.store[k] = v\n",
    "        self.order.append(k)\n",
    "        if len(self.order) > self.max_items:\n",
    "            old = self.order.pop(0)\n",
    "            self.store.pop(old, None)\n",
    "\n",
    "def _hash_prompt(prompt: str) -> str:\n",
    "    return hashlib.sha256(prompt.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _validate(dec: dict, *, full_size: int, compress_size: int, agg_ms_choices: tuple[int,...]) -> Decision:\n",
    "    # basic schema & constraints\n",
    "    a = dec.get(\"action\")\n",
    "    if a not in VALID_ACTIONS:\n",
    "        raise ValueError(f\"bad action {a}\")\n",
    "    p = dec.get(\"param\", None)\n",
    "    sz = dec.get(\"size_bytes\", None)\n",
    "\n",
    "    if a == \"AGGREGATE\":\n",
    "        if p not in agg_ms_choices or sz is not None:\n",
    "            raise ValueError(\"AGGREGATE requires paramâˆˆchoices and size_bytes=null\")\n",
    "    elif a == \"COMPRESS\":\n",
    "        if p is not None or sz != compress_size:\n",
    "            raise ValueError(\"COMPRESS requires size_bytes=compress_size and param=null\")\n",
    "    elif a == \"ALLOW\":\n",
    "        if p is not None or sz != full_size:\n",
    "            raise ValueError(\"ALLOW requires size_bytes=full_size and param=null\")\n",
    "    else:  # SKIP\n",
    "        if p is not None or sz is not None:\n",
    "            raise ValueError(\"SKIP requires both null\")\n",
    "\n",
    "    return Decision(a, p, sz)\n",
    "\n",
    "class TokenBucket:\n",
    "    \"\"\"Simple per-process rate limiter.\"\"\"\n",
    "    def __init__(self, rate_per_sec: float, burst: int):\n",
    "        self.rate = rate_per_sec\n",
    "        self.burst = burst\n",
    "        self.tokens = burst\n",
    "        self.last = time.time()\n",
    "\n",
    "    def take(self, n=1):\n",
    "        now = time.time()\n",
    "        self.tokens = min(self.burst, self.tokens + (now - self.last)*self.rate)\n",
    "        self.last = now\n",
    "        if self.tokens >= n:\n",
    "            self.tokens -= n\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def make_call_model_fn(\n",
    "    *,\n",
    "    llm_call: Callable[[str], str],\n",
    "    full_size: int,\n",
    "    compress_size: int,\n",
    "    agg_ms_choices: tuple[int,...],\n",
    "    rps: float = 10.0,\n",
    "    burst: int = 20,\n",
    "):\n",
    "    cache = LRUCache(50_000)\n",
    "    bucket = TokenBucket(rps, burst)\n",
    "\n",
    "    def _call(prompt: str) -> dict:\n",
    "        key = _hash_prompt(prompt)\n",
    "        cached = cache.get(key)\n",
    "        if cached:\n",
    "            return cached\n",
    "\n",
    "        # crude, local rate-limit\n",
    "        while not bucket.take(1):\n",
    "            time.sleep(0.02)\n",
    "\n",
    "        # call provider\n",
    "        raw = llm_call(prompt)\n",
    "        try:\n",
    "            obj = json.loads(raw)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"LLM returned non-JSON: {raw[:160]}...\") from e\n",
    "\n",
    "        dec = _validate(obj, full_size=full_size, compress_size=compress_size, agg_ms_choices=agg_ms_choices)\n",
    "        out = {\"action\": dec.action, \"param\": dec.param, \"size_bytes\": dec.size_bytes}\n",
    "        cache.put(key, out)\n",
    "        return out\n",
    "\n",
    "    return _call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e4271-05a6-4a4b-ad0f-78781f616b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
